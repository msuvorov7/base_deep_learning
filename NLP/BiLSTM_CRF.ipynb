{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d87c1935",
   "metadata": {},
   "source": [
    "Dataset https://github.com/natasha/nerus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e7771f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install navec\n",
    "# !pip install razdel\n",
    "# !pip install nerus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50e65d4",
   "metadata": {},
   "source": [
    "Embeddings https://github.com/natasha/navec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48768de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://storage.yandexcloud.net/natasha-navec/packs/navec_news_v1_1B_250K_300d_100q.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55a952b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "812d1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nerus import load_nerus\n",
    "from tqdm import tqdm\n",
    "from navec import Navec\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77d3d724",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a14f59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_nerus('nerus_lenta.conllu.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11ce8237",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "tags = []\n",
    "sentence_limit = 200_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa179d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16867it [00:27, 603.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.2 s, sys: 560 ms, total: 27.7 s\n",
      "Wall time: 28 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for doc in tqdm(docs):\n",
    "    for sent in doc.sents:\n",
    "        token_sent = []\n",
    "        tag_sent = []\n",
    "        for token in sent.tokens:\n",
    "            token_sent.append(token.text)\n",
    "            tag_sent.append(token.tag)\n",
    "        tokens.append(token_sent)\n",
    "        tags.append(tag_sent)\n",
    "    if len(tokens) > sentence_limit:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b46924d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200010"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51303263",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_entity = {\n",
    "    0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC'\n",
    "}\n",
    "entity_to_label = {value: key for key, value in label_to_entity.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44674677",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "for sent in tags:\n",
    "    labels.append([entity_to_label[tag] for tag in sent])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c6abfd",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f5293af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NerDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 tokens: list,\n",
    "                 tags: list,\n",
    "                 embedding_model,\n",
    "                 entity_to_label: dict,\n",
    "                 max_sent_len=80,\n",
    "                 pad_token='<pad>',\n",
    "                 ignoring_label=7\n",
    "                ):\n",
    "        self.embedding_model = embedding_model\n",
    "        self.tokens = tokens\n",
    "        self.tags = tags\n",
    "        self.max_sent_len = max_sent_len\n",
    "        self.entity_to_label=entity_to_label\n",
    "        self.pad = pad_token\n",
    "        self.ig_label = ignoring_label\n",
    "\n",
    "    def __getitem__(self, index):        \n",
    "        embeddings = np.array([\n",
    "            self.embedding_model.get(token.lower(), self.embedding_model['<unk>']) \n",
    "            for token in self.tokens[index]\n",
    "        ])\n",
    "        labels = np.array([self.entity_to_label[tag] for tag in self.tags[index]])\n",
    "        \n",
    "        sent_len = len(embeddings)\n",
    "        \n",
    "        if sent_len < self.max_sent_len:\n",
    "            to_pad = self.max_sent_len - sent_len\n",
    "            embeddings = np.concatenate([embeddings, [self.embedding_model[self.pad] for _ in range(to_pad)]])\n",
    "            labels = np.concatenate([labels, np.repeat(self.ig_label, to_pad)])\n",
    "        else:\n",
    "            embeddings = embeddings[:self.max_sent_len, :]\n",
    "            labels = labels[:self.max_sent_len]\n",
    "        \n",
    "        if len(labels) < 80:\n",
    "            print(index, labels)\n",
    "        return torch.FloatTensor(embeddings), torch.LongTensor(labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a16e692",
   "metadata": {},
   "outputs": [],
   "source": [
    "navec_path = 'navec_news_v1_1B_250K_300d_100q.tar'\n",
    "navec = Navec.load(navec_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c723826",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    tokens,\n",
    "    tags,\n",
    "    random_state=42,\n",
    "    test_size=0.3\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    random_state=42,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1148e9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NerDataset(\n",
    "    embedding_model=navec,\n",
    "    tokens=X_train,\n",
    "    tags=y_train,\n",
    "    entity_to_label=entity_to_label,\n",
    ")\n",
    "\n",
    "valid_dataset = NerDataset(\n",
    "    embedding_model=navec,\n",
    "    tokens=X_val,\n",
    "    tags=y_val,\n",
    "    entity_to_label=entity_to_label,\n",
    ")\n",
    "\n",
    "test_dataset = NerDataset(\n",
    "    embedding_model=navec,\n",
    "    tokens=X_test,\n",
    "    tags=y_test,\n",
    "    entity_to_label=entity_to_label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d2e761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13f47012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ранее',\n",
       " 'суд',\n",
       " 'обязал',\n",
       " 'главу',\n",
       " 'Смоленска',\n",
       " 'оплатить',\n",
       " 'штраф',\n",
       " 'в',\n",
       " 'размере',\n",
       " '60',\n",
       " 'тысяч',\n",
       " 'рублей',\n",
       " 'за',\n",
       " 'нецелевое',\n",
       " 'использование',\n",
       " 'бюджетных',\n",
       " 'областных',\n",
       " 'средств',\n",
       " ',',\n",
       " 'выделенных',\n",
       " 'на',\n",
       " 'благоустройство',\n",
       " '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[38849]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02e89c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-LOC',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[38849]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36358f39",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 80, 300])\n",
      "torch.Size([32, 80])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    print(batch[0].shape)\n",
    "    print(batch[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a56ee30",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20c0c900",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 hidden_size: int,\n",
    "                 out_size: int\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.bilstm = nn.LSTM(\n",
    "            emb_size, hidden_size, batch_first=True, bidirectional=True\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(2 * hidden_size, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x = [batch_size, sent_len, emb_dim]\n",
    "        rnn_out, _ = self.bilstm(x)  # [batch_size, sent_len, hidden_size * 2]\n",
    "        scores = self.fc(rnn_out)  # [batch_size, sent_len, out_size]\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a758fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiLSTM(\n",
    "    emb_size=300,\n",
    "    hidden_size=128,\n",
    "    out_size=len(entity_to_label) + 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3443406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 80, 8])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d418628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2560, 8])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model(batch[0])\n",
    "y_predict.view(-1, y_predict.shape[2]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6bd60153",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bf2bdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    valid_loader: DataLoader,\n",
    "    criterion: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    device: str,\n",
    "    max_grad_norm: int = 2,\n",
    ") -> (float, float):\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader):\n",
    "        text = batch[0].to(device)\n",
    "        labels = batch[1].view(-1).to(device)\n",
    "\n",
    "        y_predict = model(text)\n",
    "        loss = criterion(y_predict.view(-1, y_predict.shape[2]), labels)\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        if max_grad_norm is not None:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    y_true, y_pred, label_pred = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader):\n",
    "\n",
    "            text = batch[0].to(device)\n",
    "            labels = batch[1].view(-1).to(device)\n",
    "\n",
    "            prediction = model(text)\n",
    "            prediction = prediction.view(-1, prediction.shape[2])\n",
    "            label_predict = torch.argmax(prediction, dim=1).view(-1)\n",
    "            preds = F.softmax(prediction, dim=1)[:, 1]\n",
    "\n",
    "            y_true += labels.cpu().detach().numpy().ravel().tolist()\n",
    "            y_pred += preds.cpu().detach().numpy().ravel().tolist()\n",
    "            label_pred += label_predict.cpu().detach().numpy().ravel().tolist()\n",
    "\n",
    "            loss = criterion(prediction, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(valid_loader)\n",
    "    y_true = np.array(y_true)\n",
    "    label_pred = np.array(label_pred)\n",
    "    print(classification_report(y_true[y_true != 7], label_pred[y_true != 7]))\n",
    "\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e78ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model: nn.Module,\n",
    "         test_data_loader: DataLoader,\n",
    "         device: str,\n",
    "         ):\n",
    "\n",
    "    model.eval()\n",
    "    y_true, y_pred, label_pred = [], [], []\n",
    "    for batch in tqdm(test_data_loader):\n",
    "        text = batch[0].to(device)\n",
    "        labels = batch[1].view(-1).to(device)\n",
    "\n",
    "        prediction = model(text)\n",
    "        prediction = prediction.view(-1, prediction.shape[2])\n",
    "        label_predict = torch.argmax(prediction, dim=1).view(-1)\n",
    "        preds = F.softmax(prediction, dim=1)[:, 1]\n",
    "\n",
    "        y_true += labels.cpu().detach().numpy().ravel().tolist()\n",
    "        y_pred += preds.cpu().detach().numpy().ravel().tolist()\n",
    "        label_pred += label_predict.cpu().detach().numpy().ravel().tolist()\n",
    "        \n",
    "    y_true = np.array(y_true)\n",
    "    label_pred = np.array(label_pred)\n",
    "    print(classification_report(y_true[y_true != 7], label_pred[y_true != 7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2769dca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a2f7b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 3501/3501 [04:53<00:00, 11.94it/s]\n",
      "100%|████████████████████████████████████████████████████| 876/876 [00:39<00:00, 21.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99    459716\n",
      "           1       0.86      0.81      0.83     10161\n",
      "           2       0.87      0.87      0.87      6676\n",
      "           3       0.78      0.72      0.75     11035\n",
      "           4       0.72      0.66      0.69      8769\n",
      "           5       0.90      0.90      0.90     12346\n",
      "           6       0.84      0.69      0.75      1977\n",
      "\n",
      "    accuracy                           0.97    510680\n",
      "   macro avg       0.85      0.81      0.83    510680\n",
      "weighted avg       0.97      0.97      0.97    510680\n",
      "\n",
      "\n",
      "Epoch: 0, Training Loss: 0.1773051009155646, Validation Loss: 0.10343711142806702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 3501/3501 [05:06<00:00, 11.42it/s]\n",
      "100%|████████████████████████████████████████████████████| 876/876 [00:44<00:00, 19.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    459716\n",
      "           1       0.93      0.80      0.86     10161\n",
      "           2       0.92      0.87      0.89      6676\n",
      "           3       0.89      0.74      0.81     11035\n",
      "           4       0.87      0.64      0.74      8769\n",
      "           5       0.95      0.91      0.93     12346\n",
      "           6       0.90      0.77      0.83      1977\n",
      "\n",
      "    accuracy                           0.98    510680\n",
      "   macro avg       0.92      0.82      0.87    510680\n",
      "weighted avg       0.97      0.98      0.97    510680\n",
      "\n",
      "\n",
      "Epoch: 1, Training Loss: 0.0847997877739372, Validation Loss: 0.07772123008502911\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    train_loss, val_loss = train(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        valid_loader=valid_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        device=device\n",
    "    )\n",
    "    print()\n",
    "    print(f'Epoch: {epoch}, Training Loss: {train_loss}, Validation Loss: {val_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "983387a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 1876/1876 [01:34<00:00, 19.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99    978059\n",
      "           1       0.93      0.80      0.86     21426\n",
      "           2       0.92      0.87      0.89     14371\n",
      "           3       0.89      0.74      0.81     23446\n",
      "           4       0.88      0.65      0.75     18721\n",
      "           5       0.95      0.91      0.93     25503\n",
      "           6       0.88      0.79      0.83      3972\n",
      "\n",
      "    accuracy                           0.98   1085498\n",
      "   macro avg       0.92      0.82      0.87   1085498\n",
      "weighted avg       0.97      0.98      0.97   1085498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c138725",
   "metadata": {},
   "source": [
    "# CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a933f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_TAG = '<START>'\n",
    "STOP_TAG = '<STOP>'\n",
    "entity_to_label.update({START_TAG: 7, STOP_TAG: 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "19c9b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_CRF(nn.Module):\n",
    "\n",
    "    def __init__(self, tag_to_ix, embedding_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.tag_to_ix = tag_to_ix\n",
    "        self.tagset_size = len(tag_to_ix)\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim,\n",
    "            hidden_dim // 2,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # слой для преобразования векторного представления из LSTM в логиты сущности\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
    "\n",
    "        # матрица перехода transitions[i, j] из сущности j в сущность i\n",
    "        self.transitions = nn.Parameter(\n",
    "            torch.randn(self.tagset_size, self.tagset_size, device=self.device)\n",
    "        )\n",
    "        # устанавливаем следующие параметры для матрицы перехода\n",
    "        # делаем невозможным переход в специальный токен старт \n",
    "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
    "        # делаем невозможным переход из специального токена конец\n",
    "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
    "\n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return (torch.randn(2, 1, self.hidden_dim // 2, device=self.device),\n",
    "                torch.randn(2, 1, self.hidden_dim // 2, device=self.device))\n",
    "\n",
    "    \n",
    "    def _forward_alg(self, feats):\n",
    "        # инициализируем массив с логитами сущностей\n",
    "        init_alphas = torch.full((self.tagset_size,), -10000., device=self.device)\n",
    "        init_alphas[self.tag_to_ix[START_TAG]] = 0.\n",
    "\n",
    "        forward_var = [init_alphas,]\n",
    "\n",
    "        # аналогично прямому ходу в HHM\n",
    "        for idx, feat in enumerate(feats):\n",
    "            forwards = torch.stack([forward_var[idx]] * feats.shape[1], dim=0)  # [feats.shape[1], feats.shape[1]]\n",
    "            emmissions = feat.unsqueeze(0).transpose(0, 1)  # [feats.shape[1], 1]\n",
    "            alphas_t = forwards + emmissions + self.transitions  # [feats.shape[1], feats.shape[1]]\n",
    "            forward_var.append(torch.logsumexp(alphas_t, dim=1))\n",
    "\n",
    "        terminal_var = forward_var[-1] + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
    "        alpha = torch.logsumexp(terminal_var.unsqueeze(0), dim=1)[0]\n",
    "        return alpha\n",
    "\n",
    "    def _get_lstm_features(self, sentence):\n",
    "        self.hidden = self.init_hidden()\n",
    "        lstm_out, self.hidden = self.lstm(sentence.unsqueeze(0), self.hidden)\n",
    "        lstm_feats = self.hidden2tag(lstm_out).squeeze(0)\n",
    "        return lstm_feats\n",
    "\n",
    "    def _score_sentence(self, feats, tags):\n",
    "        # оценка реальной последовательности сущностей\n",
    "        score = torch.zeros(1, device=self.device)\n",
    "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long, device=self.device), tags])\n",
    "        for i, feat in enumerate(feats):\n",
    "            score = score + \\\n",
    "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
    "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
    "        return score\n",
    "    \n",
    "    def _viterbi_decode(self, feats):\n",
    "        # прямой и обратный ход алгоритма витерби\n",
    "        backpointers = []\n",
    "\n",
    "        init_vvars = torch.full((1, self.tagset_size,), -10000., device=self.device)\n",
    "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
    "\n",
    "        forward_var = [init_vvars,]\n",
    "        for idx, feat in enumerate(feats):\n",
    "            forwards = torch.stack([forward_var[idx]] * feats.shape[1], dim=0)  # [feats.shape[1], feats.shape[1]]\n",
    "            forwards = forwards.squeeze()\n",
    "            tags_var = forwards + self.transitions\n",
    "            viterbivars_t, bptrs_t = torch.max(tags_var, dim=1)\n",
    "            \n",
    "            next_forward_var = feat.unsqueeze(0) + viterbivars_t.unsqueeze(0)\n",
    "            forward_var.append(next_forward_var)\n",
    "            \n",
    "            backpointers.append(bptrs_t.tolist())\n",
    "        \n",
    "        terminal_var = forward_var[-1] + self.transitions[self.tag_to_ix[STOP_TAG]]  # [1, feats.shape[1]]\n",
    "        best_tag_id = torch.argmax(terminal_var).tolist()\n",
    "        path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "        # Follow the back pointers to decode the best path.\n",
    "        best_path = [best_tag_id]\n",
    "        for bptrs_t in reversed(backpointers):\n",
    "            best_tag_id = bptrs_t[best_tag_id]\n",
    "            best_path.append(best_tag_id)\n",
    "\n",
    "        # Pop off the start tag (we dont want to return that to the caller)\n",
    "        start = best_path.pop()\n",
    "        assert start == self.tag_to_ix[START_TAG]\n",
    "        best_path.reverse()\n",
    "        return path_score, best_path\n",
    "\n",
    "    def neg_log_likelihood(self, sentence, tags):\n",
    "        feats = self._get_lstm_features(sentence)\n",
    "        forward_score = self._forward_alg(feats)\n",
    "        gold_score = self._score_sentence(feats, tags)\n",
    "        return forward_score - gold_score\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        # метод для инференса (без _viterby_decode)\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_lstm_features(sentence)\n",
    "\n",
    "        # Find the best path, given the features.\n",
    "        # score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return lstm_feats, self.transitions\n",
    "    \n",
    "    def predict(self, sentence):\n",
    "        # метод для получения предсказаний на валидации\n",
    "        # Get the emission scores from the BiLSTM\n",
    "        lstm_feats = self._get_lstm_features(sentence)\n",
    "\n",
    "        # Find the best path, given the features.\n",
    "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
    "        return score, tag_seq\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b02832a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 128\n",
    "\n",
    "model = BiLSTM_CRF(entity_to_label, EMBEDDING_DIM, HIDDEN_DIM).to('cpu')\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce7100ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 80, 300])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = batch[0]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ef23159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = model._get_lstm_features(x[0])\n",
    "feats[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bea6aa33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(225.5877, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._forward_alg(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c90660ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(159.6971, grad_fn=<SelectBackward0>),\n",
       " [4,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  1,\n",
       "  2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._viterbi_decode(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3ea961c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-679996.6250], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model._score_sentence(batch[0][0], batch[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8df49bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([680222.5000], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.neg_log_likelihood(batch[0][0], batch[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bfcdb32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_LABEL = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4127512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 3501/3501 [10:42<00:00,  5.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 43.527854282288715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████| 3501/3501 [10:38<00:00,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 28.936170242677857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 2\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    train_loss = 0\n",
    "    num_iter = 0\n",
    "    model.train()\n",
    "    for batch in tqdm(train_loader):\n",
    "        num_iter += 1\n",
    "        sentences, labels = batch[0].to(device), batch[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = 0\n",
    "        for i in range(sentences.size(0)):\n",
    "\n",
    "            sentence_in = sentences[i]\n",
    "            targets = labels[i]\n",
    "            index = (targets != IGNORE_LABEL)\n",
    "\n",
    "            loss += model.neg_log_likelihood(sentence_in[index], targets[index])\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    print(f\"Train Loss: {train_loss / num_iter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a933da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "        7, 7, 7, 7, 7, 7, 7, 7])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5fd22457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3705, -0.7310, -0.4335,  ..., -0.5524, -0.2321, -0.1320],\n",
       "        [ 0.0369,  0.0933,  0.0202,  ..., -0.1182, -0.0398,  0.0157],\n",
       "        [-0.1782, -0.4132,  0.2546,  ..., -0.0679, -0.6165, -0.1322],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89153d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_feats, transitions = model(sentence_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c22aaa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi_decode(feats, transitions):\n",
    "    tagset_size = len(transitions)\n",
    "    # прямой и обратный ход алгоритма витерби\n",
    "    backpointers = []\n",
    "\n",
    "    init_vvars = np.full((1, tagset_size,), -10000.)\n",
    "    init_vvars[0][entity_to_label[START_TAG]] = 0\n",
    "\n",
    "    forward_var = [init_vvars,]\n",
    "    for idx, feat in enumerate(feats):\n",
    "        forwards = np.stack([forward_var[idx]] * feats.shape[1], axis=0)  # [feats.shape[1], feats.shape[1]]\n",
    "        forwards = forwards.squeeze()\n",
    "        tags_var = forwards + transitions\n",
    "        viterbivars_t = np.max(tags_var, axis=1)\n",
    "        bptrs_t = np.argmax(tags_var, axis=1)\n",
    "\n",
    "        next_forward_var = feat[np.newaxis, :] + viterbivars_t[np.newaxis, :]\n",
    "        forward_var.append(next_forward_var)\n",
    "\n",
    "        backpointers.append(bptrs_t.tolist())\n",
    "\n",
    "    terminal_var = forward_var[-1] + transitions[entity_to_label[STOP_TAG]]  # [1, feats.shape[1]]\n",
    "    best_tag_id = np.argmax(terminal_var).tolist()\n",
    "    path_score = terminal_var[0][best_tag_id]\n",
    "\n",
    "    # Follow the back pointers to decode the best path.\n",
    "    best_path = [best_tag_id]\n",
    "    for bptrs_t in reversed(backpointers):\n",
    "        best_tag_id = bptrs_t[best_tag_id]\n",
    "        best_path.append(best_tag_id)\n",
    "\n",
    "    # Pop off the start tag (we dont want to return that to the caller)\n",
    "    start = best_path.pop()\n",
    "    assert start == entity_to_label[START_TAG]\n",
    "    best_path.reverse()\n",
    "    return path_score, best_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d966122",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356.8219148516655,\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  0,\n",
       "  0])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi_decode(lstm_feats.detach().cpu().numpy(), transitions.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "12689a10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(356.1121, grad_fn=<SelectBackward0>),\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  4,\n",
       "  0])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(sentence_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "635b4d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, iterator):\n",
    "    valid_loss = 0\n",
    "    num_iter = 0\n",
    "    valid_acc = 0\n",
    "    num_words = 0\n",
    "    labels_ = []\n",
    "    predicts = []\n",
    "    model.eval()\n",
    "    for batch in tqdm(iterator, total=len(iterator)):\n",
    "        num_iter += 1\n",
    "        sentences, labels = batch[0].to(device), batch[1].to(device)\n",
    "        with torch.no_grad():\n",
    "            loss = 0\n",
    "            for i in range(sentences.size(0)):\n",
    "                sentence_in = sentences[i]\n",
    "                targets = labels[i]\n",
    "                index = (targets != IGNORE_LABEL)\n",
    "                num_words += len(targets[index])\n",
    "\n",
    "                loss += model.neg_log_likelihood(sentence_in[index], targets[index])\n",
    "                _, prediction = model.predict(sentence_in[index])\n",
    "                valid_acc += (targets[index] == prediction)\n",
    "                labels_.extend(targets[index].cpu().detach().tolist())\n",
    "                predicts.extend(prediction)\n",
    "            valid_loss += loss.item()\n",
    "            \n",
    "    print(classification_report(labels_, predicts))\n",
    "    return valid_loss / num_words, valid_acc / num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b8d5ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 876/876 [01:52<00:00,  7.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    459716\n",
      "           1       0.94      0.83      0.88     10161\n",
      "           2       0.90      0.88      0.89      6676\n",
      "           3       0.84      0.81      0.82     11035\n",
      "           4       0.64      0.84      0.73      8769\n",
      "           5       0.96      0.92      0.94     12346\n",
      "           6       0.90      0.80      0.85      1977\n",
      "\n",
      "    accuracy                           0.97    510680\n",
      "   macro avg       0.88      0.87      0.87    510680\n",
      "weighted avg       0.98      0.97      0.97    510680\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.05469495396723508, 0.0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1d0614",
   "metadata": {},
   "source": [
    "# ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "232022d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 80, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "13483729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([80, 9])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(dummy_input[0])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1c492606",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ruasvmv/common/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:4476: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================ Diagnostic Run torch.onnx.export version 2.0.1 ================\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input[0],\n",
    "    'ner.onnx',\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={'input': {0: 'seq_len'}, 'output': {0: 'seq_len', 1: 'tagset_dim'}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "021fae5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnxruntime.InferenceSession('ner.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "00bb87b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<onnxruntime.capi.onnxruntime_pybind11_state.NodeArg at 0x1110eba30>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnx_model.get_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2e916ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = {onnx_model.get_inputs()[0].name: np.random.randn(20, 300).astype(np.float32)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "294dd2d1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_output = onnx_model.run(None, model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "14c1fc56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 9)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad4abe79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.4997542e+00,  1.7855476e+00, -1.7697632e+00, -4.7236148e-01,\n",
       "         -8.3279902e-01, -7.7576518e+00, -1.6556206e+00, -2.6764913e-04,\n",
       "         -1.1226005e-03],\n",
       "        [ 2.0506878e+00, -4.9079509e+00, -3.2761295e+00, -2.8434510e+00,\n",
       "          2.2662246e+00, -3.5639086e+00,  4.6917143e+00,  5.2528240e-04,\n",
       "         -3.7918118e-04],\n",
       "        [ 3.5871267e+00, -5.9086881e+00, -5.7697926e+00, -9.7056150e-01,\n",
       "         -8.2546610e-01, -5.2151737e+00, -1.5465969e+00,  2.3082382e-04,\n",
       "         -8.8623993e-04],\n",
       "        [ 1.2331828e+00,  1.9994755e-01, -2.0941973e+00,  5.4416053e-02,\n",
       "          1.3272123e+00, -6.8608751e+00, -1.2029495e+00, -7.0299325e-04,\n",
       "          6.7429013e-05],\n",
       "        [ 2.8996274e+00,  6.1644837e-02, -1.4424642e+00,  7.5732328e-02,\n",
       "         -3.4712012e+00, -2.0634651e+00, -5.6706367e+00,  9.5449784e-04,\n",
       "          3.5029376e-04],\n",
       "        [ 5.2019191e+00, -6.4175868e+00, -3.8840194e+00, -2.5222335e+00,\n",
       "         -8.1722307e-01, -5.2342296e+00, -4.3930826e+00, -7.7542459e-04,\n",
       "          2.0741917e-04],\n",
       "        [ 2.4594066e+00, -3.4340167e+00, -3.2891359e+00,  6.7051131e-01,\n",
       "         -2.4351275e+00,  3.8489437e-01, -3.1595523e+00, -2.4430582e-04,\n",
       "          9.1312663e-04],\n",
       "        [ 3.8286164e+00, -3.6882644e+00, -4.3557634e+00, -5.2713138e-01,\n",
       "         -1.9992599e+00, -4.5163522e+00, -1.4480226e+00, -5.6671677e-04,\n",
       "          7.1422663e-05],\n",
       "        [ 1.7911748e+00, -6.5257907e+00, -6.1958899e+00,  2.7338561e-01,\n",
       "          2.8245382e+00, -5.1598034e+00,  4.4591193e+00, -9.5706206e-04,\n",
       "         -6.2819177e-05],\n",
       "        [ 2.1484814e+00, -5.0461030e+00, -3.5859051e+00,  2.4510002e-01,\n",
       "          3.1755370e-01, -4.9526854e+00,  2.6529126e+00, -4.7647057e-04,\n",
       "          1.3191291e-04],\n",
       "        [ 2.2484694e+00, -1.1888905e+00, -1.5809757e-01, -1.2242460e-01,\n",
       "         -3.7409687e+00, -2.6135640e+00,  3.6901500e+00, -5.6444702e-04,\n",
       "          2.7181331e-05],\n",
       "        [ 1.2625864e+00, -1.7900883e+00, -8.9770353e-01,  1.8178920e+00,\n",
       "         -1.6385276e+00, -3.9849973e+00,  3.5096350e+00, -2.3046027e-04,\n",
       "         -8.6684719e-05],\n",
       "        [ 1.7867229e+00, -1.1660377e+00, -1.9767694e+00, -6.8857771e-01,\n",
       "         -4.0489477e-01, -2.5571194e+00, -3.3689125e+00,  3.9126701e-04,\n",
       "         -6.0008664e-04],\n",
       "        [ 1.4771168e-01, -2.3453224e+00, -1.6566379e+00,  6.0694585e+00,\n",
       "         -1.1843805e+00, -3.2910075e+00, -1.4605352e+00,  5.6241971e-04,\n",
       "         -2.6611593e-05],\n",
       "        [ 2.8018746e-01, -2.8731711e+00, -4.8942837e-01, -1.4397354e-01,\n",
       "          1.6580064e+00, -2.3935499e+00, -2.7057850e+00, -1.3043660e-03,\n",
       "          3.0152549e-04],\n",
       "        [ 3.6880145e+00, -5.6970134e+00, -3.0436273e+00, -2.1111481e+00,\n",
       "         -1.8755221e+00, -3.2896628e+00, -4.1998506e+00, -3.3596170e-04,\n",
       "         -3.3106229e-05],\n",
       "        [ 3.6755779e+00, -7.8954697e+00, -5.7992091e+00, -1.8944812e-01,\n",
       "         -1.9421319e+00, -2.5874287e-01, -4.9150176e+00, -6.6811842e-04,\n",
       "          3.2495180e-04],\n",
       "        [ 2.0751650e+00,  6.3237935e-02,  7.4188006e-01, -1.4751791e+00,\n",
       "         -1.6545751e+00, -2.3469076e+00, -5.4594445e+00, -2.4162469e-04,\n",
       "          7.9451065e-04],\n",
       "        [ 4.2166209e+00, -5.6049194e+00, -4.9549723e+00, -6.0422707e-01,\n",
       "         -1.7973044e+00, -4.0414190e+00, -3.5651393e+00, -1.6740181e-04,\n",
       "          1.3637402e-04],\n",
       "        [ 5.2016463e+00, -2.8817613e+00, -5.5244379e+00, -4.8102064e+00,\n",
       "         -3.6841348e-01, -7.9728379e+00, -5.4525155e-01,  1.5578982e-04,\n",
       "         -4.6476407e-04]], dtype=float32),\n",
       " array([[ 6.7621291e-01, -8.9534217e-01, -8.9330322e-01, -9.7845769e-01,\n",
       "         -1.4622777e+00,  3.2449850e-01, -8.4554476e-01,  1.6778022e+00,\n",
       "         -9.9316211e+03],\n",
       "        [ 1.4262173e+00, -2.7039890e+00, -1.5551784e+00, -4.7296783e-01,\n",
       "         -4.2995986e-01,  1.7424401e+00,  5.9291756e-01,  2.7372584e+00,\n",
       "         -9.9316211e+03],\n",
       "        [-5.3947926e+00,  3.9726803e+00,  2.3799558e+00, -5.6955628e+00,\n",
       "         -5.7818775e+00, -3.5316412e+00, -3.3837228e+00, -4.6133566e+00,\n",
       "         -9.9316211e+03],\n",
       "        [ 7.9095995e-01, -2.5525868e+00, -2.5914743e+00, -2.2573977e+00,\n",
       "         -1.2097586e+00, -6.6820300e-01, -1.1689507e+00,  1.2875701e+00,\n",
       "         -9.9316211e+03],\n",
       "        [-7.0810380e+00, -2.1985104e+00, -3.6070046e+00,  3.8841884e+00,\n",
       "          3.4331248e+00, -2.2999132e+00, -2.9879816e+00, -3.8521962e+00,\n",
       "         -9.9316211e+03],\n",
       "        [ 1.3733668e+00, -1.4442642e+00, -5.2407354e-01, -3.4534237e-01,\n",
       "          7.0812720e-01, -3.2654992e-01, -1.2750051e+00,  1.1287894e+00,\n",
       "         -9.9316211e+03],\n",
       "        [-8.5195055e+00, -3.5122917e+00, -2.7104104e+00, -5.8224449e+00,\n",
       "         -6.0506825e+00,  3.7346535e+00,  1.7303067e+00, -3.3256633e+00,\n",
       "         -9.9316211e+03],\n",
       "        [-9.9316211e+03, -9.9316211e+03, -9.9316211e+03, -9.9316211e+03,\n",
       "         -9.9316211e+03, -9.9316211e+03, -9.9316211e+03, -9.9316211e+03,\n",
       "         -9.9316211e+03],\n",
       "        [ 3.7498980e+00, -4.7741308e+00, -3.6172855e+00, -2.7551687e+00,\n",
       "         -1.8192811e+00, -3.1311877e+00, -3.0014915e+00, -5.1592278e-38,\n",
       "         -9.9316211e+03]], dtype=float32)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d20abe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85.00238877534866,\n",
       " [0, 0, 0, 0, 0, 0, 5, 6, 6, 6, 6, 6, 0, 3, 4, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "viterbi_decode(model_output[0], model_output[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94db8bc",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a7707f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'В библиотеке имени Ленина разгорелся скандал с участием Сергея Миронова'\n",
    "tokenized = test.lower().split()\n",
    "embedded = np.array([navec.get(token, navec['<unk>']) for token in tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8e135955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 300)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "77b37a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = {onnx_model.get_inputs()[0].name: embedded.astype(np.float32)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "455af579",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = onnx_model.run(None, model_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cc6e3842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 9)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "70825644",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, labels = viterbi_decode(model_output[0], model_output[1])\n",
    "tags = [label_to_entity[label] for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "496fc213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'в': 'O',\n",
       " 'библиотеке': 'O',\n",
       " 'имени': 'O',\n",
       " 'ленина': 'O',\n",
       " 'разгорелся': 'O',\n",
       " 'скандал': 'O',\n",
       " 'с': 'O',\n",
       " 'участием': 'O',\n",
       " 'сергея': 'B-PER',\n",
       " 'миронова': 'I-PER'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(tokenized, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b939db7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
